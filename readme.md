# ICP: Immediate Compensation Pruning for Midâ€‘toâ€‘High Sparsity

Official implementation for the paper **â€œICP: Immediate Compensation Pruning for Midâ€‘toâ€‘High Sparsity.â€**
([arXiv link â€• coming soon](#))

> *XinÂ Luo, XuemingÂ Fu, ZihangÂ Jiang, S.â€¯KevinÂ Zhou*
> University of Science and Technology of China, MIRACLEÂ Center & CASÂ ICT

---

## ğŸ“ Overview

ICP strikes a middle ground between costly iterative pruning and purely oneâ€‘shot pruning by **compensating interâ€‘block errors onâ€‘theâ€‘fly**.
Key highlights:

| Feature                           | Description                                                                                               |
| --------------------------------- | --------------------------------------------------------------------------------------------------------- |
| **Blockâ€‘wise CompensateÂ Pruning** | Alternating *pruneÂ â†’ compensate* in a sliding window of two Transformer blocks, preventing error cascade. |
| **Sparsity Rearrangement**        | Reâ€‘allocates sparsity both *between* blocks (Î±) and *within* a block (Î²) to minimise uncompensated error. |
| **Language & Vision support**     | Works outâ€‘ofâ€‘theâ€‘box on OPT/Llama (NLP) **and** SAM (CV) backbones.                                       |
| **Memoryâ€‘friendly**               | Only one block resides on GPU at any time; runs on a single RTXÂ 3090 (24Â GB).                             |

Extensive experiments show superior perplexity / accuracy / IoU versus SparseGPT, Wanda, and magnitude pruning across sparsity **50â€“90â€¯%** and mixed 2:4 / 4:8 + int3/int4 compression.

---

## ğŸ“‚ Repository Structure

```
â”œâ”€â”€ icp_sam.py        # ICP for Segment Anything Model
â”œâ”€â”€ icp_opt.py        # ICP for OPT language models
â”œâ”€â”€ icp_llama.py      # ICP for Llama / Llamaâ€‘2 models
â”œâ”€â”€ bash/             # Oneâ€‘click scripts with tuned hyperâ€‘parameters
â”œâ”€â”€ segment_anything/ # Minimal SAM dependency (copied from Meta)
â”œâ”€â”€ data_utils.py | feature_utils.py | ...
â””â”€â”€ README.md         # <â€” you are here
```

*All other files are auxiliary helpers (loading, evaluation, quantisation, etc.).*

---

## âš™ï¸ Requirements

* PythonÂ â‰¥Â 3.9
* PyTorchÂ â‰¥Â 2.1 (CUDAÂ 11.8)
* transformers â‰¥Â 4.41
* accelerate, einops, datasets, tqdm,Â â€¦

Create an environment (example):

```bash
conda create -n icp python=3.10 pytorch=2.2.2 cuda=11.8 -c pytorch -c nvidia
conda activate icp
pip install -r requirements.txt  # list provided
```

---

## ğŸ“¥ Checkpoints & Datasets

* **OPT / Llama models** are autoâ€‘downloaded from HuggingÂ Face on first run.
* **SAM models** â€• download the Meta SAM checkpoints and COCOÂ 2017 + SAâ€‘1B splits:
  `sa_000001.tar`, `sa_000003.tar` â†’ extract to `sa_000001/`, `sa_000003/` and update the paths below.

---

## ğŸš€ Quick Start

```bash
# Language models
bash icp_opt.sh      # prune OPTâ€‘125M/1.3B/2.7B/6.7B
bash icp_llama.sh    # prune Llamaâ€‘2â€‘7B

# Vision model
bash icp_sam.sh      # prune SAMâ€‘B/L/H
```

Each script exposes CLI flags for sparsity (`--sparsity`), block window (`--alpha`), intraâ€‘block Î², calibration size, epochs, quantisation bits, etc.

---

## â–¶ï¸ **Run Instructions (fill in later)**

> *TODO: LuoÂ Xin â€“ please paste the detailed stepâ€‘byâ€‘step commands here (training, evaluation, reproducing tables 1â€‘8).*
> The section is intentionally left blank for your upcoming notes.

---

## ğŸ“Š Results

---

## âœï¸ Citation

```bibtex
@inproceedings{luo2025icp,
  title     = {ICP: Immediate Compensation Pruning for Mid-to-High Sparsity},
  author    = {Xin Luo and Xueming Fu and Zihang Jiang and S. Kevin Zhou},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2025}
}
```

---

## ğŸ›¡ License

This repository is released under the **CC BYâ€‘NCÂ 4.0** license â€” free for research & nonâ€‘commercial use.
See the [LICENSE](LICENSE) file for the full text.

---

## ğŸ¤ Acknowledgements

Parts of the code are adapted from [SparseGPT](https://github.com/IST-DASLab/sparsegpt), [Wanda](https://github.com/locuslab/wanda) and Metaâ€™s [segment-anything](https://github.com/facebookresearch/segment-anything). We thank the openâ€‘source community!
